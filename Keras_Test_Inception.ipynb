{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://deeplearningsandbox.com/how-to-use-transfer-learning-and-fine-tuning-in-keras-and-tensorflow-to-build-an-image-recognition-94b0b02444f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "NB_EPOCHS = 3\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172\n",
    "\n",
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        print(layer.name, ': ', layer.trainable)\n",
    "    # model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "      Args:\n",
    "        base_model: keras model excluding top\n",
    "        nb_classes: # of classes\n",
    "      Returns:\n",
    "        new keras model with last layer\n",
    "    \"\"\"\n",
    "    \n",
    "    x = base_model.output\n",
    "\n",
    "    # GlobalAveragePooling2D converts the MxNxC tensor output into a 1xC tensor where C is the # of channels.\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) # new FC layer, random init\n",
    "    # softmax function on the output to squeeze the values between [0,1]\n",
    "    #predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_to_finetune(model):\n",
    "    \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top layers.\n",
    "  note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "  Args:\n",
    "    model: keras model\n",
    "  \"\"\"\n",
    "    for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    # model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
    "    \n",
    "    nb_train_samples = 2000\n",
    "    nb_classes = 2\n",
    "    nb_val_samples = 800\n",
    "    nb_epoch = 10\n",
    "    batch_size = 16\n",
    "    train_dir = 'data-pets/train'\n",
    "    val_dir = 'data-pets/validation'\n",
    "    output_model_file = 'inceptionv3.h5'\n",
    "\n",
    "    # data prep\n",
    "    train_datagen = ImageDataGenerator(\n",
    "          preprocessing_function=preprocess_input, # zero-centers our image data\n",
    "          rotation_range=30,\n",
    "          width_shift_range=0.2,\n",
    "          height_shift_range=0.2,\n",
    "          shear_range=0.2,\n",
    "          zoom_range=0.2,\n",
    "          horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    "          preprocessing_function=preprocess_input,\n",
    "          rotation_range=30,\n",
    "          width_shift_range=0.2,\n",
    "          height_shift_range=0.2,\n",
    "          shear_range=0.2,\n",
    "          zoom_range=0.2,\n",
    "          horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # setup model\n",
    "    # leave out the weights of the last fully connected layer\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "    \n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "\n",
    "    history_tl = model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=5,\n",
    "        steps_per_epoch=nb_train_samples//batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_val_samples//batch_size\n",
    "        #,\n",
    "        #class_weight='auto'\n",
    "    )\n",
    "    \n",
    "    # fine-tuning\n",
    "    setup_to_finetune(model)\n",
    "    \n",
    "    history_ft = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples//batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_val_samples//batch_size\n",
    "        #,\n",
    "        #class_weight='auto'\n",
    "    )\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(\"incep_filter.json\", 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    model.save(output_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "input_12 :  False\n",
      "conv2d_1035 :  False\n",
      "batch_normalization_1035 :  False\n",
      "activation_1035 :  False\n",
      "conv2d_1036 :  False\n",
      "batch_normalization_1036 :  False\n",
      "activation_1036 :  False\n",
      "conv2d_1037 :  False\n",
      "batch_normalization_1037 :  False\n",
      "activation_1037 :  False\n",
      "max_pooling2d_45 :  False\n",
      "conv2d_1038 :  False\n",
      "batch_normalization_1038 :  False\n",
      "activation_1038 :  False\n",
      "conv2d_1039 :  False\n",
      "batch_normalization_1039 :  False\n",
      "activation_1039 :  False\n",
      "max_pooling2d_46 :  False\n",
      "conv2d_1043 :  False\n",
      "batch_normalization_1043 :  False\n",
      "activation_1043 :  False\n",
      "conv2d_1041 :  False\n",
      "conv2d_1044 :  False\n",
      "batch_normalization_1041 :  False\n",
      "batch_normalization_1044 :  False\n",
      "activation_1041 :  False\n",
      "activation_1044 :  False\n",
      "average_pooling2d_100 :  False\n",
      "conv2d_1040 :  False\n",
      "conv2d_1042 :  False\n",
      "conv2d_1045 :  False\n",
      "conv2d_1046 :  False\n",
      "batch_normalization_1040 :  False\n",
      "batch_normalization_1042 :  False\n",
      "batch_normalization_1045 :  False\n",
      "batch_normalization_1046 :  False\n",
      "activation_1040 :  False\n",
      "activation_1042 :  False\n",
      "activation_1045 :  False\n",
      "activation_1046 :  False\n",
      "mixed0 :  False\n",
      "conv2d_1050 :  False\n",
      "batch_normalization_1050 :  False\n",
      "activation_1050 :  False\n",
      "conv2d_1048 :  False\n",
      "conv2d_1051 :  False\n",
      "batch_normalization_1048 :  False\n",
      "batch_normalization_1051 :  False\n",
      "activation_1048 :  False\n",
      "activation_1051 :  False\n",
      "average_pooling2d_101 :  False\n",
      "conv2d_1047 :  False\n",
      "conv2d_1049 :  False\n",
      "conv2d_1052 :  False\n",
      "conv2d_1053 :  False\n",
      "batch_normalization_1047 :  False\n",
      "batch_normalization_1049 :  False\n",
      "batch_normalization_1052 :  False\n",
      "batch_normalization_1053 :  False\n",
      "activation_1047 :  False\n",
      "activation_1049 :  False\n",
      "activation_1052 :  False\n",
      "activation_1053 :  False\n",
      "mixed1 :  False\n",
      "conv2d_1057 :  False\n",
      "batch_normalization_1057 :  False\n",
      "activation_1057 :  False\n",
      "conv2d_1055 :  False\n",
      "conv2d_1058 :  False\n",
      "batch_normalization_1055 :  False\n",
      "batch_normalization_1058 :  False\n",
      "activation_1055 :  False\n",
      "activation_1058 :  False\n",
      "average_pooling2d_102 :  False\n",
      "conv2d_1054 :  False\n",
      "conv2d_1056 :  False\n",
      "conv2d_1059 :  False\n",
      "conv2d_1060 :  False\n",
      "batch_normalization_1054 :  False\n",
      "batch_normalization_1056 :  False\n",
      "batch_normalization_1059 :  False\n",
      "batch_normalization_1060 :  False\n",
      "activation_1054 :  False\n",
      "activation_1056 :  False\n",
      "activation_1059 :  False\n",
      "activation_1060 :  False\n",
      "mixed2 :  False\n",
      "conv2d_1062 :  False\n",
      "batch_normalization_1062 :  False\n",
      "activation_1062 :  False\n",
      "conv2d_1063 :  False\n",
      "batch_normalization_1063 :  False\n",
      "activation_1063 :  False\n",
      "conv2d_1061 :  False\n",
      "conv2d_1064 :  False\n",
      "batch_normalization_1061 :  False\n",
      "batch_normalization_1064 :  False\n",
      "activation_1061 :  False\n",
      "activation_1064 :  False\n",
      "max_pooling2d_47 :  False\n",
      "mixed3 :  False\n",
      "conv2d_1069 :  False\n",
      "batch_normalization_1069 :  False\n",
      "activation_1069 :  False\n",
      "conv2d_1070 :  False\n",
      "batch_normalization_1070 :  False\n",
      "activation_1070 :  False\n",
      "conv2d_1066 :  False\n",
      "conv2d_1071 :  False\n",
      "batch_normalization_1066 :  False\n",
      "batch_normalization_1071 :  False\n",
      "activation_1066 :  False\n",
      "activation_1071 :  False\n",
      "conv2d_1067 :  False\n",
      "conv2d_1072 :  False\n",
      "batch_normalization_1067 :  False\n",
      "batch_normalization_1072 :  False\n",
      "activation_1067 :  False\n",
      "activation_1072 :  False\n",
      "average_pooling2d_103 :  False\n",
      "conv2d_1065 :  False\n",
      "conv2d_1068 :  False\n",
      "conv2d_1073 :  False\n",
      "conv2d_1074 :  False\n",
      "batch_normalization_1065 :  False\n",
      "batch_normalization_1068 :  False\n",
      "batch_normalization_1073 :  False\n",
      "batch_normalization_1074 :  False\n",
      "activation_1065 :  False\n",
      "activation_1068 :  False\n",
      "activation_1073 :  False\n",
      "activation_1074 :  False\n",
      "mixed4 :  False\n",
      "conv2d_1079 :  False\n",
      "batch_normalization_1079 :  False\n",
      "activation_1079 :  False\n",
      "conv2d_1080 :  False\n",
      "batch_normalization_1080 :  False\n",
      "activation_1080 :  False\n",
      "conv2d_1076 :  False\n",
      "conv2d_1081 :  False\n",
      "batch_normalization_1076 :  False\n",
      "batch_normalization_1081 :  False\n",
      "activation_1076 :  False\n",
      "activation_1081 :  False\n",
      "conv2d_1077 :  False\n",
      "conv2d_1082 :  False\n",
      "batch_normalization_1077 :  False\n",
      "batch_normalization_1082 :  False\n",
      "activation_1077 :  False\n",
      "activation_1082 :  False\n",
      "average_pooling2d_104 :  False\n",
      "conv2d_1075 :  False\n",
      "conv2d_1078 :  False\n",
      "conv2d_1083 :  False\n",
      "conv2d_1084 :  False\n",
      "batch_normalization_1075 :  False\n",
      "batch_normalization_1078 :  False\n",
      "batch_normalization_1083 :  False\n",
      "batch_normalization_1084 :  False\n",
      "activation_1075 :  False\n",
      "activation_1078 :  False\n",
      "activation_1083 :  False\n",
      "activation_1084 :  False\n",
      "mixed5 :  False\n",
      "conv2d_1089 :  False\n",
      "batch_normalization_1089 :  False\n",
      "activation_1089 :  False\n",
      "conv2d_1090 :  False\n",
      "batch_normalization_1090 :  False\n",
      "activation_1090 :  False\n",
      "conv2d_1086 :  False\n",
      "conv2d_1091 :  False\n",
      "batch_normalization_1086 :  False\n",
      "batch_normalization_1091 :  False\n",
      "activation_1086 :  False\n",
      "activation_1091 :  False\n",
      "conv2d_1087 :  False\n",
      "conv2d_1092 :  False\n",
      "batch_normalization_1087 :  False\n",
      "batch_normalization_1092 :  False\n",
      "activation_1087 :  False\n",
      "activation_1092 :  False\n",
      "average_pooling2d_105 :  False\n",
      "conv2d_1085 :  False\n",
      "conv2d_1088 :  False\n",
      "conv2d_1093 :  False\n",
      "conv2d_1094 :  False\n",
      "batch_normalization_1085 :  False\n",
      "batch_normalization_1088 :  False\n",
      "batch_normalization_1093 :  False\n",
      "batch_normalization_1094 :  False\n",
      "activation_1085 :  False\n",
      "activation_1088 :  False\n",
      "activation_1093 :  False\n",
      "activation_1094 :  False\n",
      "mixed6 :  False\n",
      "conv2d_1099 :  False\n",
      "batch_normalization_1099 :  False\n",
      "activation_1099 :  False\n",
      "conv2d_1100 :  False\n",
      "batch_normalization_1100 :  False\n",
      "activation_1100 :  False\n",
      "conv2d_1096 :  False\n",
      "conv2d_1101 :  False\n",
      "batch_normalization_1096 :  False\n",
      "batch_normalization_1101 :  False\n",
      "activation_1096 :  False\n",
      "activation_1101 :  False\n",
      "conv2d_1097 :  False\n",
      "conv2d_1102 :  False\n",
      "batch_normalization_1097 :  False\n",
      "batch_normalization_1102 :  False\n",
      "activation_1097 :  False\n",
      "activation_1102 :  False\n",
      "average_pooling2d_106 :  False\n",
      "conv2d_1095 :  False\n",
      "conv2d_1098 :  False\n",
      "conv2d_1103 :  False\n",
      "conv2d_1104 :  False\n",
      "batch_normalization_1095 :  False\n",
      "batch_normalization_1098 :  False\n",
      "batch_normalization_1103 :  False\n",
      "batch_normalization_1104 :  False\n",
      "activation_1095 :  False\n",
      "activation_1098 :  False\n",
      "activation_1103 :  False\n",
      "activation_1104 :  False\n",
      "mixed7 :  False\n",
      "conv2d_1107 :  False\n",
      "batch_normalization_1107 :  False\n",
      "activation_1107 :  False\n",
      "conv2d_1108 :  False\n",
      "batch_normalization_1108 :  False\n",
      "activation_1108 :  False\n",
      "conv2d_1105 :  False\n",
      "conv2d_1109 :  False\n",
      "batch_normalization_1105 :  False\n",
      "batch_normalization_1109 :  False\n",
      "activation_1105 :  False\n",
      "activation_1109 :  False\n",
      "conv2d_1106 :  False\n",
      "conv2d_1110 :  False\n",
      "batch_normalization_1106 :  False\n",
      "batch_normalization_1110 :  False\n",
      "activation_1106 :  False\n",
      "activation_1110 :  False\n",
      "max_pooling2d_48 :  False\n",
      "mixed8 :  False\n",
      "conv2d_1115 :  False\n",
      "batch_normalization_1115 :  False\n",
      "activation_1115 :  False\n",
      "conv2d_1112 :  False\n",
      "conv2d_1116 :  False\n",
      "batch_normalization_1112 :  False\n",
      "batch_normalization_1116 :  False\n",
      "activation_1112 :  False\n",
      "activation_1116 :  False\n",
      "conv2d_1113 :  False\n",
      "conv2d_1114 :  False\n",
      "conv2d_1117 :  False\n",
      "conv2d_1118 :  False\n",
      "average_pooling2d_107 :  False\n",
      "conv2d_1111 :  False\n",
      "batch_normalization_1113 :  False\n",
      "batch_normalization_1114 :  False\n",
      "batch_normalization_1117 :  False\n",
      "batch_normalization_1118 :  False\n",
      "conv2d_1119 :  False\n",
      "batch_normalization_1111 :  False\n",
      "activation_1113 :  False\n",
      "activation_1114 :  False\n",
      "activation_1117 :  False\n",
      "activation_1118 :  False\n",
      "batch_normalization_1119 :  False\n",
      "activation_1111 :  False\n",
      "mixed9_0 :  False\n",
      "concatenate_23 :  False\n",
      "activation_1119 :  False\n",
      "mixed9 :  False\n",
      "conv2d_1124 :  False\n",
      "batch_normalization_1124 :  False\n",
      "activation_1124 :  False\n",
      "conv2d_1121 :  False\n",
      "conv2d_1125 :  False\n",
      "batch_normalization_1121 :  False\n",
      "batch_normalization_1125 :  False\n",
      "activation_1121 :  False\n",
      "activation_1125 :  False\n",
      "conv2d_1122 :  False\n",
      "conv2d_1123 :  False\n",
      "conv2d_1126 :  False\n",
      "conv2d_1127 :  False\n",
      "average_pooling2d_108 :  False\n",
      "conv2d_1120 :  False\n",
      "batch_normalization_1122 :  False\n",
      "batch_normalization_1123 :  False\n",
      "batch_normalization_1126 :  False\n",
      "batch_normalization_1127 :  False\n",
      "conv2d_1128 :  False\n",
      "batch_normalization_1120 :  False\n",
      "activation_1122 :  False\n",
      "activation_1123 :  False\n",
      "activation_1126 :  False\n",
      "activation_1127 :  False\n",
      "batch_normalization_1128 :  False\n",
      "activation_1120 :  False\n",
      "mixed9_1 :  False\n",
      "concatenate_24 :  False\n",
      "activation_1128 :  False\n",
      "mixed10 :  False\n",
      "global_average_pooling2d_10 :  True\n",
      "dense_19 :  True\n",
      "dense_20 :  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 81s - loss: 2.4970 - acc: 0.7080 - val_loss: 0.0938 - val_acc: 0.9700\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 77s - loss: 0.3367 - acc: 0.8705 - val_loss: 0.0954 - val_acc: 0.9613\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 77s - loss: 0.2603 - acc: 0.9115 - val_loss: 0.0820 - val_acc: 0.9663\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 77s - loss: 0.2101 - acc: 0.9130 - val_loss: 0.0950 - val_acc: 0.9637\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 77s - loss: 0.2245 - acc: 0.9155 - val_loss: 0.0945 - val_acc: 0.9575\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 117s - loss: 0.1236 - acc: 0.9510 - val_loss: 0.0841 - val_acc: 0.9650\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 112s - loss: 0.0893 - acc: 0.9650 - val_loss: 0.0632 - val_acc: 0.9725\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 112s - loss: 0.0948 - acc: 0.9600 - val_loss: 0.0663 - val_acc: 0.9762\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 113s - loss: 0.0998 - acc: 0.9620 - val_loss: 0.0738 - val_acc: 0.9675\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 113s - loss: 0.0789 - acc: 0.9720 - val_loss: 0.0641 - val_acc: 0.9788\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
