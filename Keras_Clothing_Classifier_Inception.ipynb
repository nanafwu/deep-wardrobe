{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://deeplearningsandbox.com/how-to-use-transfer-learning-and-fine-tuning-in-keras-and-tensorflow-to-build-an-image-recognition-94b0b02444f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172 # unfreeze the top 2 inception blocks\n",
    "\n",
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        print(layer.name, ': ', layer.trainable)\n",
    "    model.compile(optimizer=RMSprop(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "      Args:\n",
    "        base_model: keras model excluding top\n",
    "        nb_classes: # of classes\n",
    "      Returns:\n",
    "        new keras model with last layer\n",
    "    \"\"\"\n",
    "    \n",
    "    x = base_model.output\n",
    "\n",
    "    # GlobalAveragePooling2D converts the MxNxC tensor output into a 1xC tensor where C is the # of channels.\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) # new FC layer, random init\n",
    "    # softmax function on the output to squeeze the values between [0,1]\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_to_finetune(model):\n",
    "    \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top layers.\n",
    "  note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "  Args:\n",
    "    model: keras model\n",
    "  \"\"\"\n",
    "    for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
    "    \n",
    "    nb_train_samples = 45000\n",
    "    nb_classes = 15\n",
    "    nb_val_samples = 15000\n",
    "    nb_epoch = 15\n",
    "    batch_size = 4 #16\n",
    "    train_dir = 'data-all/train'\n",
    "    val_dir = 'data-all/validation'\n",
    "    output_model_file = 'inceptionv3_clothing_expanded_classifier.h5'\n",
    "\n",
    "    # data prep\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input, # zero-centers our image data\n",
    "        # rescale = 1./255,\n",
    "#           rotation_range=30,\n",
    "#           width_shift_range=0.2,\n",
    "#           height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # setup model\n",
    "    # leave out the weights of the last fully connected layer\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "    \n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "\n",
    "    history_tl = model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=nb_epoch,\n",
    "        steps_per_epoch=nb_train_samples//batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_val_samples//batch_size\n",
    "        #,\n",
    "        #class_weight='auto'\n",
    "    )\n",
    "    \n",
    "    print('Begin Fine Tuning')\n",
    "    # fine-tuning\n",
    "    setup_to_finetune(model)\n",
    "    \n",
    "    history_ft = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples//batch_size,\n",
    "        epochs=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_val_samples//batch_size\n",
    "        #,\n",
    "        #class_weight='auto'\n",
    "    )\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(\"incep_filter_clothing_expanded_classifier.json\", 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    model.save(output_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44999 images belonging to 15 classes.\n",
      "Found 15000 images belonging to 15 classes.\n",
      "input_4 :  False\n",
      "conv2d_234 :  False\n",
      "batch_normalization_233 :  False\n",
      "activation_233 :  False\n",
      "conv2d_235 :  False\n",
      "batch_normalization_234 :  False\n",
      "activation_234 :  False\n",
      "conv2d_236 :  False\n",
      "batch_normalization_235 :  False\n",
      "activation_235 :  False\n",
      "max_pooling2d_12 :  False\n",
      "conv2d_237 :  False\n",
      "batch_normalization_236 :  False\n",
      "activation_236 :  False\n",
      "conv2d_238 :  False\n",
      "batch_normalization_237 :  False\n",
      "activation_237 :  False\n",
      "max_pooling2d_13 :  False\n",
      "conv2d_242 :  False\n",
      "batch_normalization_241 :  False\n",
      "activation_241 :  False\n",
      "conv2d_240 :  False\n",
      "conv2d_243 :  False\n",
      "batch_normalization_239 :  False\n",
      "batch_normalization_242 :  False\n",
      "activation_239 :  False\n",
      "activation_242 :  False\n",
      "average_pooling2d_23 :  False\n",
      "conv2d_239 :  False\n",
      "conv2d_241 :  False\n",
      "conv2d_244 :  False\n",
      "conv2d_245 :  False\n",
      "batch_normalization_238 :  False\n",
      "batch_normalization_240 :  False\n",
      "batch_normalization_243 :  False\n",
      "batch_normalization_244 :  False\n",
      "activation_238 :  False\n",
      "activation_240 :  False\n",
      "activation_243 :  False\n",
      "activation_244 :  False\n",
      "mixed0 :  False\n",
      "conv2d_249 :  False\n",
      "batch_normalization_248 :  False\n",
      "activation_248 :  False\n",
      "conv2d_247 :  False\n",
      "conv2d_250 :  False\n",
      "batch_normalization_246 :  False\n",
      "batch_normalization_249 :  False\n",
      "activation_246 :  False\n",
      "activation_249 :  False\n",
      "average_pooling2d_24 :  False\n",
      "conv2d_246 :  False\n",
      "conv2d_248 :  False\n",
      "conv2d_251 :  False\n",
      "conv2d_252 :  False\n",
      "batch_normalization_245 :  False\n",
      "batch_normalization_247 :  False\n",
      "batch_normalization_250 :  False\n",
      "batch_normalization_251 :  False\n",
      "activation_245 :  False\n",
      "activation_247 :  False\n",
      "activation_250 :  False\n",
      "activation_251 :  False\n",
      "mixed1 :  False\n",
      "conv2d_256 :  False\n",
      "batch_normalization_255 :  False\n",
      "activation_255 :  False\n",
      "conv2d_254 :  False\n",
      "conv2d_257 :  False\n",
      "batch_normalization_253 :  False\n",
      "batch_normalization_256 :  False\n",
      "activation_253 :  False\n",
      "activation_256 :  False\n",
      "average_pooling2d_25 :  False\n",
      "conv2d_253 :  False\n",
      "conv2d_255 :  False\n",
      "conv2d_258 :  False\n",
      "conv2d_259 :  False\n",
      "batch_normalization_252 :  False\n",
      "batch_normalization_254 :  False\n",
      "batch_normalization_257 :  False\n",
      "batch_normalization_258 :  False\n",
      "activation_252 :  False\n",
      "activation_254 :  False\n",
      "activation_257 :  False\n",
      "activation_258 :  False\n",
      "mixed2 :  False\n",
      "conv2d_261 :  False\n",
      "batch_normalization_260 :  False\n",
      "activation_260 :  False\n",
      "conv2d_262 :  False\n",
      "batch_normalization_261 :  False\n",
      "activation_261 :  False\n",
      "conv2d_260 :  False\n",
      "conv2d_263 :  False\n",
      "batch_normalization_259 :  False\n",
      "batch_normalization_262 :  False\n",
      "activation_259 :  False\n",
      "activation_262 :  False\n",
      "max_pooling2d_14 :  False\n",
      "mixed3 :  False\n",
      "conv2d_268 :  False\n",
      "batch_normalization_267 :  False\n",
      "activation_267 :  False\n",
      "conv2d_269 :  False\n",
      "batch_normalization_268 :  False\n",
      "activation_268 :  False\n",
      "conv2d_265 :  False\n",
      "conv2d_270 :  False\n",
      "batch_normalization_264 :  False\n",
      "batch_normalization_269 :  False\n",
      "activation_264 :  False\n",
      "activation_269 :  False\n",
      "conv2d_266 :  False\n",
      "conv2d_271 :  False\n",
      "batch_normalization_265 :  False\n",
      "batch_normalization_270 :  False\n",
      "activation_265 :  False\n",
      "activation_270 :  False\n",
      "average_pooling2d_26 :  False\n",
      "conv2d_264 :  False\n",
      "conv2d_267 :  False\n",
      "conv2d_272 :  False\n",
      "conv2d_273 :  False\n",
      "batch_normalization_263 :  False\n",
      "batch_normalization_266 :  False\n",
      "batch_normalization_271 :  False\n",
      "batch_normalization_272 :  False\n",
      "activation_263 :  False\n",
      "activation_266 :  False\n",
      "activation_271 :  False\n",
      "activation_272 :  False\n",
      "mixed4 :  False\n",
      "conv2d_278 :  False\n",
      "batch_normalization_277 :  False\n",
      "activation_277 :  False\n",
      "conv2d_279 :  False\n",
      "batch_normalization_278 :  False\n",
      "activation_278 :  False\n",
      "conv2d_275 :  False\n",
      "conv2d_280 :  False\n",
      "batch_normalization_274 :  False\n",
      "batch_normalization_279 :  False\n",
      "activation_274 :  False\n",
      "activation_279 :  False\n",
      "conv2d_276 :  False\n",
      "conv2d_281 :  False\n",
      "batch_normalization_275 :  False\n",
      "batch_normalization_280 :  False\n",
      "activation_275 :  False\n",
      "activation_280 :  False\n",
      "average_pooling2d_27 :  False\n",
      "conv2d_274 :  False\n",
      "conv2d_277 :  False\n",
      "conv2d_282 :  False\n",
      "conv2d_283 :  False\n",
      "batch_normalization_273 :  False\n",
      "batch_normalization_276 :  False\n",
      "batch_normalization_281 :  False\n",
      "batch_normalization_282 :  False\n",
      "activation_273 :  False\n",
      "activation_276 :  False\n",
      "activation_281 :  False\n",
      "activation_282 :  False\n",
      "mixed5 :  False\n",
      "conv2d_288 :  False\n",
      "batch_normalization_287 :  False\n",
      "activation_287 :  False\n",
      "conv2d_289 :  False\n",
      "batch_normalization_288 :  False\n",
      "activation_288 :  False\n",
      "conv2d_285 :  False\n",
      "conv2d_290 :  False\n",
      "batch_normalization_284 :  False\n",
      "batch_normalization_289 :  False\n",
      "activation_284 :  False\n",
      "activation_289 :  False\n",
      "conv2d_286 :  False\n",
      "conv2d_291 :  False\n",
      "batch_normalization_285 :  False\n",
      "batch_normalization_290 :  False\n",
      "activation_285 :  False\n",
      "activation_290 :  False\n",
      "average_pooling2d_28 :  False\n",
      "conv2d_284 :  False\n",
      "conv2d_287 :  False\n",
      "conv2d_292 :  False\n",
      "conv2d_293 :  False\n",
      "batch_normalization_283 :  False\n",
      "batch_normalization_286 :  False\n",
      "batch_normalization_291 :  False\n",
      "batch_normalization_292 :  False\n",
      "activation_283 :  False\n",
      "activation_286 :  False\n",
      "activation_291 :  False\n",
      "activation_292 :  False\n",
      "mixed6 :  False\n",
      "conv2d_298 :  False\n",
      "batch_normalization_297 :  False\n",
      "activation_297 :  False\n",
      "conv2d_299 :  False\n",
      "batch_normalization_298 :  False\n",
      "activation_298 :  False\n",
      "conv2d_295 :  False\n",
      "conv2d_300 :  False\n",
      "batch_normalization_294 :  False\n",
      "batch_normalization_299 :  False\n",
      "activation_294 :  False\n",
      "activation_299 :  False\n",
      "conv2d_296 :  False\n",
      "conv2d_301 :  False\n",
      "batch_normalization_295 :  False\n",
      "batch_normalization_300 :  False\n",
      "activation_295 :  False\n",
      "activation_300 :  False\n",
      "average_pooling2d_29 :  False\n",
      "conv2d_294 :  False\n",
      "conv2d_297 :  False\n",
      "conv2d_302 :  False\n",
      "conv2d_303 :  False\n",
      "batch_normalization_293 :  False\n",
      "batch_normalization_296 :  False\n",
      "batch_normalization_301 :  False\n",
      "batch_normalization_302 :  False\n",
      "activation_293 :  False\n",
      "activation_296 :  False\n",
      "activation_301 :  False\n",
      "activation_302 :  False\n",
      "mixed7 :  False\n",
      "conv2d_306 :  False\n",
      "batch_normalization_305 :  False\n",
      "activation_305 :  False\n",
      "conv2d_307 :  False\n",
      "batch_normalization_306 :  False\n",
      "activation_306 :  False\n",
      "conv2d_304 :  False\n",
      "conv2d_308 :  False\n",
      "batch_normalization_303 :  False\n",
      "batch_normalization_307 :  False\n",
      "activation_303 :  False\n",
      "activation_307 :  False\n",
      "conv2d_305 :  False\n",
      "conv2d_309 :  False\n",
      "batch_normalization_304 :  False\n",
      "batch_normalization_308 :  False\n",
      "activation_304 :  False\n",
      "activation_308 :  False\n",
      "max_pooling2d_15 :  False\n",
      "mixed8 :  False\n",
      "conv2d_314 :  False\n",
      "batch_normalization_313 :  False\n",
      "activation_313 :  False\n",
      "conv2d_311 :  False\n",
      "conv2d_315 :  False\n",
      "batch_normalization_310 :  False\n",
      "batch_normalization_314 :  False\n",
      "activation_310 :  False\n",
      "activation_314 :  False\n",
      "conv2d_312 :  False\n",
      "conv2d_313 :  False\n",
      "conv2d_316 :  False\n",
      "conv2d_317 :  False\n",
      "average_pooling2d_30 :  False\n",
      "conv2d_310 :  False\n",
      "batch_normalization_311 :  False\n",
      "batch_normalization_312 :  False\n",
      "batch_normalization_315 :  False\n",
      "batch_normalization_316 :  False\n",
      "conv2d_318 :  False\n",
      "batch_normalization_309 :  False\n",
      "activation_311 :  False\n",
      "activation_312 :  False\n",
      "activation_315 :  False\n",
      "activation_316 :  False\n",
      "batch_normalization_317 :  False\n",
      "activation_309 :  False\n",
      "mixed9_0 :  False\n",
      "concatenate_5 :  False\n",
      "activation_317 :  False\n",
      "mixed9 :  False\n",
      "conv2d_323 :  False\n",
      "batch_normalization_322 :  False\n",
      "activation_322 :  False\n",
      "conv2d_320 :  False\n",
      "conv2d_324 :  False\n",
      "batch_normalization_319 :  False\n",
      "batch_normalization_323 :  False\n",
      "activation_319 :  False\n",
      "activation_323 :  False\n",
      "conv2d_321 :  False\n",
      "conv2d_322 :  False\n",
      "conv2d_325 :  False\n",
      "conv2d_326 :  False\n",
      "average_pooling2d_31 :  False\n",
      "conv2d_319 :  False\n",
      "batch_normalization_320 :  False\n",
      "batch_normalization_321 :  False\n",
      "batch_normalization_324 :  False\n",
      "batch_normalization_325 :  False\n",
      "conv2d_327 :  False\n",
      "batch_normalization_318 :  False\n",
      "activation_320 :  False\n",
      "activation_321 :  False\n",
      "activation_324 :  False\n",
      "activation_325 :  False\n",
      "batch_normalization_326 :  False\n",
      "activation_318 :  False\n",
      "mixed9_1 :  False\n",
      "concatenate_6 :  False\n",
      "activation_326 :  False\n",
      "mixed10 :  False\n",
      "global_average_pooling2d_3 :  True\n",
      "dense_5 :  True\n",
      "dense_6 :  True\n",
      "Epoch 1/15\n",
      "11250/11250 [==============================] - 2286s - loss: 1.5958 - acc: 0.5364 - val_loss: 0.9745 - val_acc: 0.6983\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250/11250 [==============================] - 2276s - loss: 1.1573 - acc: 0.6384 - val_loss: 0.8446 - val_acc: 0.7325\n",
      "Epoch 3/15\n",
      "11250/11250 [==============================] - 2276s - loss: 1.0790 - acc: 0.6586 - val_loss: 0.7997 - val_acc: 0.7408\n",
      "Epoch 4/15\n",
      "11250/11250 [==============================] - 2279s - loss: 1.0392 - acc: 0.6727 - val_loss: 0.8058 - val_acc: 0.7425\n",
      "Epoch 5/15\n",
      "11250/11250 [==============================] - 2286s - loss: 1.0042 - acc: 0.6814 - val_loss: 0.7682 - val_acc: 0.7517\n",
      "Epoch 6/15\n",
      "11250/11250 [==============================] - 2281s - loss: 0.9862 - acc: 0.6871 - val_loss: 0.7574 - val_acc: 0.7566\n",
      "Epoch 7/15\n",
      "11250/11250 [==============================] - 2283s - loss: 0.9721 - acc: 0.6901 - val_loss: 0.7462 - val_acc: 0.7597\n",
      "Epoch 8/15\n",
      "11250/11250 [==============================] - 2279s - loss: 0.9521 - acc: 0.6955 - val_loss: 0.7543 - val_acc: 0.7605\n",
      "Epoch 9/15\n",
      "11250/11250 [==============================] - 2279s - loss: 0.9410 - acc: 0.6989 - val_loss: 0.7582 - val_acc: 0.7593\n",
      "Epoch 10/15\n",
      "11250/11250 [==============================] - 2283s - loss: 0.9374 - acc: 0.6994 - val_loss: 0.7659 - val_acc: 0.7635\n",
      "Epoch 11/15\n",
      "11250/11250 [==============================] - 2279s - loss: 0.9220 - acc: 0.7076 - val_loss: 0.7433 - val_acc: 0.7651\n",
      "Epoch 12/15\n",
      "11250/11250 [==============================] - 2280s - loss: 0.9109 - acc: 0.7090 - val_loss: 0.7346 - val_acc: 0.7693\n",
      "Epoch 13/15\n",
      "11250/11250 [==============================] - 2282s - loss: 0.9066 - acc: 0.7098 - val_loss: 0.7377 - val_acc: 0.7707\n",
      "Epoch 14/15\n",
      "11250/11250 [==============================] - 2284s - loss: 0.8922 - acc: 0.7129 - val_loss: 0.7481 - val_acc: 0.7697\n",
      "Epoch 15/15\n",
      "11250/11250 [==============================] - 2283s - loss: 0.9039 - acc: 0.7104 - val_loss: 0.7430 - val_acc: 0.7713\n",
      "Begin Fine Tuning\n",
      "Epoch 1/15\n",
      "11250/11250 [==============================] - 3508s - loss: 0.8288 - acc: 0.7496 - val_loss: 0.5294 - val_acc: 0.8499\n",
      "Epoch 2/15\n",
      "11250/11250 [==============================] - 3512s - loss: 0.5151 - acc: 0.8325 - val_loss: 0.4399 - val_acc: 0.8710\n",
      "Epoch 3/15\n",
      "11250/11250 [==============================] - 3521s - loss: 0.4273 - acc: 0.8605 - val_loss: 0.4955 - val_acc: 0.8644\n",
      "Epoch 4/15\n",
      "11250/11250 [==============================] - 3521s - loss: 0.3815 - acc: 0.8736 - val_loss: 0.3975 - val_acc: 0.8875\n",
      "Epoch 5/15\n",
      "11250/11250 [==============================] - 3520s - loss: 0.3416 - acc: 0.8856 - val_loss: 0.3986 - val_acc: 0.8890\n",
      "Epoch 6/15\n",
      "11250/11250 [==============================] - 3509s - loss: 0.3160 - acc: 0.8938 - val_loss: 0.3929 - val_acc: 0.8903\n",
      "Epoch 7/15\n",
      "11250/11250 [==============================] - 3508s - loss: 0.2929 - acc: 0.9014 - val_loss: 0.4139 - val_acc: 0.8883\n",
      "Epoch 8/15\n",
      "11250/11250 [==============================] - 3510s - loss: 0.2747 - acc: 0.9077 - val_loss: 0.3906 - val_acc: 0.8901\n",
      "Epoch 9/15\n",
      "11250/11250 [==============================] - 3515s - loss: 0.2544 - acc: 0.9137 - val_loss: 0.4232 - val_acc: 0.8867\n",
      "Epoch 10/15\n",
      "11250/11250 [==============================] - 3520s - loss: 0.2371 - acc: 0.9192 - val_loss: 0.3987 - val_acc: 0.8927\n",
      "Epoch 11/15\n",
      "11250/11250 [==============================] - 3521s - loss: 0.2196 - acc: 0.9229 - val_loss: 0.4391 - val_acc: 0.8813\n",
      "Epoch 12/15\n",
      "11250/11250 [==============================] - 3516s - loss: 0.2088 - acc: 0.9292 - val_loss: 0.4348 - val_acc: 0.8832\n",
      "Epoch 13/15\n",
      "11250/11250 [==============================] - 3519s - loss: 0.2014 - acc: 0.9308 - val_loss: 0.4215 - val_acc: 0.8880\n",
      "Epoch 14/15\n",
      "11250/11250 [==============================] - 3521s - loss: 0.1868 - acc: 0.9341 - val_loss: 0.4340 - val_acc: 0.8855\n",
      "Epoch 15/15\n",
      "11250/11250 [==============================] - 3516s - loss: 0.1758 - acc: 0.9393 - val_loss: 0.4352 - val_acc: 0.8895\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Basic Clothing Classifier\n",
    "- Epoch 1/10\n",
    "7500/7500 [==============================] - 1521s - loss: 1.6899 - acc: 0.4530 - val_loss: 1.2355 - val_acc: 0.6033\n",
    "- Epoch 2/10\n",
    "7500/7500 [==============================] - 1516s - loss: 1.3493 - acc: 0.5525 - val_loss: 1.0849 - val_acc: 0.6403\n",
    "- Epoch 3/10\n",
    "7500/7500 [==============================] - 1516s - loss: 1.2620 - acc: 0.5773 - val_loss: 1.0180 - val_acc: 0.6596\n",
    "- Epoch 4/10\n",
    "7500/7500 [==============================] - 1516s - loss: 1.2161 - acc: 0.5904 - val_loss: 1.0001 - val_acc: 0.6623\n",
    "- Epoch 5/10\n",
    "7500/7500 [==============================] - 1516s - loss: 1.1917 - acc: 0.5996 - val_loss: 0.9620 - val_acc: 0.6761\n",
    "- Epoch 6/10\n",
    "7500/7500 [==============================] - 1516s - loss: 1.1749 - acc: 0.6036 - val_loss: 0.9482 - val_acc: 0.6784\n",
    "- Epoch 7/10\n",
    "7500/7500 [==============================] - 1516s - loss: 1.1600 - acc: 0.6087 - val_loss: 0.9682 - val_acc: 0.6797\n",
    "- Epoch 8/10\n",
    "7500/7500 [==============================] - 1517s - loss: 1.1409 - acc: 0.6126 - val_loss: 0.9424 - val_acc: 0.6864\n",
    "- Epoch 9/10\n",
    "7500/7500 [==============================] - 1521s - loss: 1.1387 - acc: 0.6142 - val_loss: 0.9183 - val_acc: 0.6915\n",
    "- Epoch 10/10\n",
    "7500/7500 [==============================] - 1518s - loss: 1.1330 - acc: 0.6178 - val_loss: 0.9403 - val_acc: 0.6893\n",
    "Begin Fine Tuning\n",
    "- Epoch 1/10\n",
    "7500/7500 [==============================] - 2327s - loss: 1.0142 - acc: 0.6676 - val_loss: 0.6162 - val_acc: 0.7978\n",
    "- Epoch 2/10\n",
    "7500/7500 [==============================] - 2333s - loss: 0.6800 - acc: 0.7705 - val_loss: 0.6005 - val_acc: 0.8130\n",
    "- Epoch 3/10\n",
    "7500/7500 [==============================] - 2333s - loss: 0.5676 - acc: 0.8071 - val_loss: 0.5178 - val_acc: 0.8349\n",
    "- Epoch 4/10\n",
    "7500/7500 [==============================] - 2333s - loss: 0.5044 - acc: 0.8279 - val_loss: 0.5559 - val_acc: 0.8302\n",
    "- Epoch 5/10\n",
    "7500/7500 [==============================] - 2333s - loss: 0.4558 - acc: 0.8435 - val_loss: 0.4924 - val_acc: 0.8420\n",
    "- Epoch 6/10\n",
    "7500/7500 [==============================] - 2333s - loss: 0.4254 - acc: 0.8535 - val_loss: 0.4852 - val_acc: 0.8448\n",
    "- Epoch 7/10\n",
    "7500/7500 [==============================] - 2333s - loss: 0.3930 - acc: 0.8653 - val_loss: 0.5180 - val_acc: 0.8360\n",
    "- Epoch 8/10\n",
    "7500/7500 [==============================] - 2333s - loss: 0.3661 - acc: 0.8741 - val_loss: 0.4862 - val_acc: 0.8535\n",
    "- Epoch 9/10\n",
    "7500/7500 [==============================] - 2333s - loss: 0.3428 - acc: 0.8802 - val_loss: 0.4830 - val_acc: 0.8547\n",
    "- Epoch 10/10\n",
    "7500/7500 [==============================] - 2334s - loss: 0.3217 - acc: 0.8877 - val_loss: 0.5089 - val_acc: 0.8519"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Expanded Clothing Classifier\n",
    "Epoch 1/15\n",
    "11250/11250 [==============================] - 2286s - loss: 1.5958 - acc: 0.5364 - val_loss: 0.9745 - val_acc: 0.6983\n",
    "Epoch 2/15\n",
    "11250/11250 [==============================] - 2276s - loss: 1.1573 - acc: 0.6384 - val_loss: 0.8446 - val_acc: 0.7325\n",
    "Epoch 3/15\n",
    "11250/11250 [==============================] - 2276s - loss: 1.0790 - acc: 0.6586 - val_loss: 0.7997 - val_acc: 0.7408\n",
    "Epoch 4/15\n",
    "11250/11250 [==============================] - 2279s - loss: 1.0392 - acc: 0.6727 - val_loss: 0.8058 - val_acc: 0.7425\n",
    "Epoch 5/15\n",
    "11250/11250 [==============================] - 2286s - loss: 1.0042 - acc: 0.6814 - val_loss: 0.7682 - val_acc: 0.7517\n",
    "Epoch 6/15\n",
    "11250/11250 [==============================] - 2281s - loss: 0.9862 - acc: 0.6871 - val_loss: 0.7574 - val_acc: 0.7566\n",
    "Epoch 7/15\n",
    "11250/11250 [==============================] - 2283s - loss: 0.9721 - acc: 0.6901 - val_loss: 0.7462 - val_acc: 0.7597\n",
    "Epoch 8/15\n",
    "11250/11250 [==============================] - 2279s - loss: 0.9521 - acc: 0.6955 - val_loss: 0.7543 - val_acc: 0.7605\n",
    "Epoch 9/15\n",
    "11250/11250 [==============================] - 2279s - loss: 0.9410 - acc: 0.6989 - val_loss: 0.7582 - val_acc: 0.7593\n",
    "Epoch 10/15\n",
    "11250/11250 [==============================] - 2283s - loss: 0.9374 - acc: 0.6994 - val_loss: 0.7659 - val_acc: 0.7635\n",
    "Epoch 11/15\n",
    "11250/11250 [==============================] - 2279s - loss: 0.9220 - acc: 0.7076 - val_loss: 0.7433 - val_acc: 0.7651\n",
    "Epoch 12/15\n",
    "11250/11250 [==============================] - 2280s - loss: 0.9109 - acc: 0.7090 - val_loss: 0.7346 - val_acc: 0.7693\n",
    "Epoch 13/15\n",
    "11250/11250 [==============================] - 2282s - loss: 0.9066 - acc: 0.7098 - val_loss: 0.7377 - val_acc: 0.7707\n",
    "Epoch 14/15\n",
    "11250/11250 [==============================] - 2284s - loss: 0.8922 - acc: 0.7129 - val_loss: 0.7481 - val_acc: 0.7697\n",
    "Epoch 15/15\n",
    "11250/11250 [==============================] - 2283s - loss: 0.9039 - acc: 0.7104 - val_loss: 0.7430 - val_acc: 0.7713\n",
    "Begin Fine Tuning\n",
    "Epoch 1/15\n",
    "11250/11250 [==============================] - 3508s - loss: 0.8288 - acc: 0.7496 - val_loss: 0.5294 - val_acc: 0.8499\n",
    "Epoch 2/15\n",
    "11250/11250 [==============================] - 3512s - loss: 0.5151 - acc: 0.8325 - val_loss: 0.4399 - val_acc: 0.8710\n",
    "Epoch 3/15\n",
    "11250/11250 [==============================] - 3521s - loss: 0.4273 - acc: 0.8605 - val_loss: 0.4955 - val_acc: 0.8644\n",
    "Epoch 4/15\n",
    "11250/11250 [==============================] - 3521s - loss: 0.3815 - acc: 0.8736 - val_loss: 0.3975 - val_acc: 0.8875\n",
    "Epoch 5/15\n",
    "11250/11250 [==============================] - 3520s - loss: 0.3416 - acc: 0.8856 - val_loss: 0.3986 - val_acc: 0.8890\n",
    "Epoch 6/15\n",
    "11250/11250 [==============================] - 3509s - loss: 0.3160 - acc: 0.8938 - val_loss: 0.3929 - val_acc: 0.8903\n",
    "Epoch 7/15\n",
    "11250/11250 [==============================] - 3508s - loss: 0.2929 - acc: 0.9014 - val_loss: 0.4139 - val_acc: 0.8883\n",
    "Epoch 8/15\n",
    "11250/11250 [==============================] - 3510s - loss: 0.2747 - acc: 0.9077 - val_loss: 0.3906 - val_acc: 0.8901\n",
    "Epoch 9/15\n",
    "11250/11250 [==============================] - 3515s - loss: 0.2544 - acc: 0.9137 - val_loss: 0.4232 - val_acc: 0.8867\n",
    "Epoch 10/15\n",
    "11250/11250 [==============================] - 3520s - loss: 0.2371 - acc: 0.9192 - val_loss: 0.3987 - val_acc: 0.8927\n",
    "Epoch 11/15\n",
    "11250/11250 [==============================] - 3521s - loss: 0.2196 - acc: 0.9229 - val_loss: 0.4391 - val_acc: 0.8813\n",
    "Epoch 12/15\n",
    "11250/11250 [==============================] - 3516s - loss: 0.2088 - acc: 0.9292 - val_loss: 0.4348 - val_acc: 0.8832\n",
    "Epoch 13/15\n",
    "11250/11250 [==============================] - 3519s - loss: 0.2014 - acc: 0.9308 - val_loss: 0.4215 - val_acc: 0.8880\n",
    "Epoch 14/15\n",
    "11250/11250 [==============================] - 3521s - loss: 0.1868 - acc: 0.9341 - val_loss: 0.4340 - val_acc: 0.8855\n",
    "Epoch 15/15\n",
    "11250/11250 [==============================] - 3516s - loss: 0.1758 - acc: 0.9393 - val_loss: 0.4352 - val_acc: 0.8895\n",
    "Basic Clothing Classifier\n",
    "Epoch 1/10 7500/7500 [==============================] - 1521s - loss: 1.6899 - acc: 0.4530 - val_loss: 1.2355 - val_acc: 0.6033\n",
    "Epoch 2/10 7500/7500 [==============================] - 1516s - loss: 1.3493 - acc: 0.5525 - val_loss: 1.0849 - val_acc: 0.6403\n",
    "Epoch 3/10 7500/7500 [==============================] - 1516s - loss: 1.2620 - acc: 0.5773 - val_loss: 1.0180 - val_acc: 0.6596\n",
    "Epoch 4/10 7500/7500 [==============================] - 1516s - loss: 1.2161 - acc: 0.5904 - val_loss: 1.0001 - val_acc: 0.6623\n",
    "Epoch 5/10 7500/7500 [==============================] - 1516s - loss: 1.1917 - acc: 0.5996 - val_loss: 0.9620 - val_acc: 0.6761\n",
    "Epoch 6/10 7500/7500 [==============================] - 1516s - loss: 1.1749 - acc: 0.6036 - val_loss: 0.9482 - val_acc: 0.6784\n",
    "Epoch 7/10 7500/7500 [==============================] - 1516s - loss: 1.1600 - acc: 0.6087 - val_loss: 0.9682 - val_acc: 0.6797\n",
    "Epoch 8/10 7500/7500 [==============================] - 1517s - loss: 1.1409 - acc: 0.6126 - val_loss: 0.9424 - val_acc: 0.6864\n",
    "Epoch 9/10 7500/7500 [==============================] - 1521s - loss: 1.1387 - acc: 0.6142 - val_loss: 0.9183 - val_acc: 0.6915\n",
    "Epoch 10/10 7500/7500 [==============================] - 1518s - loss: 1.1330 - acc: 0.6178 - val_loss: 0.9403 - val_acc: 0.6893 Begin Fine Tuning\n",
    "Epoch 1/10 7500/7500 [==============================] - 2327s - loss: 1.0142 - acc: 0.6676 - val_loss: 0.6162 - val_acc: 0.7978\n",
    "Epoch 2/10 7500/7500 [==============================] - 2333s - loss: 0.6800 - acc: 0.7705 - val_loss: 0.6005 - val_acc: 0.8130\n",
    "Epoch 3/10 7500/7500 [==============================] - 2333s - loss: 0.5676 - acc: 0.8071 - val_loss: 0.5178 - val_acc: 0.8349\n",
    "Epoch 4/10 7500/7500 [==============================] - 2333s - loss: 0.5044 - acc: 0.8279 - val_loss: 0.5559 - val_acc: 0.8302\n",
    "Epoch 5/10 7500/7500 [==============================] - 2333s - loss: 0.4558 - acc: 0.8435 - val_loss: 0.4924 - val_acc: 0.8420\n",
    "Epoch 6/10 7500/7500 [==============================] - 2333s - loss: 0.4254 - acc: 0.8535 - val_loss: 0.4852 - val_acc: 0.8448\n",
    "Epoch 7/10 7500/7500 [==============================] - 2333s - loss: 0.3930 - acc: 0.8653 - val_loss: 0.5180 - val_acc: 0.8360\n",
    "Epoch 8/10 7500/7500 [==============================] - 2333s - loss: 0.3661 - acc: 0.8741 - val_loss: 0.4862 - val_acc: 0.8535\n",
    "Epoch 9/10 7500/7500 [==============================] - 2333s - loss: 0.3428 - acc: 0.8802 - val_loss: 0.4830 - val_acc: 0.8547\n",
    "Epoch 10/10 7500/7500 [==============================] - 2334s - loss: 0.3217 - acc: 0.8877 - val_loss: 0.5089 - val_acc: 0.8519\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
