{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://deeplearningsandbox.com/how-to-use-transfer-learning-and-fine-tuning-in-keras-and-tensorflow-to-build-an-image-recognition-94b0b02444f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172 # unfreeze the top 2 inception blocks\n",
    "\n",
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        print(layer.name, ': ', layer.trainable)\n",
    "    model.compile(optimizer=RMSprop(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "      Args:\n",
    "        base_model: keras model excluding top\n",
    "        nb_classes: # of classes\n",
    "      Returns:\n",
    "        new keras model with last layer\n",
    "    \"\"\"\n",
    "    \n",
    "    x = base_model.output\n",
    "\n",
    "    # GlobalAveragePooling2D converts the MxNxC tensor output into a 1xC tensor where C is the # of channels.\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) # new FC layer, random init\n",
    "    # softmax function on the output to squeeze the values between [0,1]\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_to_finetune(model):\n",
    "    \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top layers.\n",
    "  note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "  Args:\n",
    "    model: keras model\n",
    "  \"\"\"\n",
    "    for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
    "    \n",
    "    nb_train_samples = 5000\n",
    "    nb_classes = 10\n",
    "    nb_val_samples = 1000\n",
    "    nb_epoch = 10\n",
    "    batch_size = 4 #16\n",
    "    train_dir = 'data/train'\n",
    "    val_dir = 'data/validation'\n",
    "    output_model_file = 'inceptionv3_clothing_classifier.h5'\n",
    "\n",
    "    # data prep\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input, # zero-centers our image data\n",
    "        # rescale = 1./255,\n",
    "#           rotation_range=30,\n",
    "#           width_shift_range=0.2,\n",
    "#           height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # setup model\n",
    "    # leave out the weights of the last fully connected layer\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "    \n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "\n",
    "    history_tl = model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=nb_epoch,\n",
    "        steps_per_epoch=nb_train_samples//batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_val_samples//batch_size\n",
    "        #,\n",
    "        #class_weight='auto'\n",
    "    )\n",
    "    \n",
    "    print('Begin Fine Tuning')\n",
    "    # fine-tuning\n",
    "    setup_to_finetune(model)\n",
    "    \n",
    "    history_ft = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples//batch_size,\n",
    "        epochs=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_val_samples//batch_size\n",
    "        #,\n",
    "        #class_weight='auto'\n",
    "    )\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(\"incep_filter_clothing_classifier.json\", 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    model.save(output_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "input_1 :  False\n",
      "conv2d_1 :  False\n",
      "batch_normalization_1 :  False\n",
      "activation_1 :  False\n",
      "conv2d_2 :  False\n",
      "batch_normalization_2 :  False\n",
      "activation_2 :  False\n",
      "conv2d_3 :  False\n",
      "batch_normalization_3 :  False\n",
      "activation_3 :  False\n",
      "max_pooling2d_1 :  False\n",
      "conv2d_4 :  False\n",
      "batch_normalization_4 :  False\n",
      "activation_4 :  False\n",
      "conv2d_5 :  False\n",
      "batch_normalization_5 :  False\n",
      "activation_5 :  False\n",
      "max_pooling2d_2 :  False\n",
      "conv2d_9 :  False\n",
      "batch_normalization_9 :  False\n",
      "activation_9 :  False\n",
      "conv2d_7 :  False\n",
      "conv2d_10 :  False\n",
      "batch_normalization_7 :  False\n",
      "batch_normalization_10 :  False\n",
      "activation_7 :  False\n",
      "activation_10 :  False\n",
      "average_pooling2d_1 :  False\n",
      "conv2d_6 :  False\n",
      "conv2d_8 :  False\n",
      "conv2d_11 :  False\n",
      "conv2d_12 :  False\n",
      "batch_normalization_6 :  False\n",
      "batch_normalization_8 :  False\n",
      "batch_normalization_11 :  False\n",
      "batch_normalization_12 :  False\n",
      "activation_6 :  False\n",
      "activation_8 :  False\n",
      "activation_11 :  False\n",
      "activation_12 :  False\n",
      "mixed0 :  False\n",
      "conv2d_16 :  False\n",
      "batch_normalization_16 :  False\n",
      "activation_16 :  False\n",
      "conv2d_14 :  False\n",
      "conv2d_17 :  False\n",
      "batch_normalization_14 :  False\n",
      "batch_normalization_17 :  False\n",
      "activation_14 :  False\n",
      "activation_17 :  False\n",
      "average_pooling2d_2 :  False\n",
      "conv2d_13 :  False\n",
      "conv2d_15 :  False\n",
      "conv2d_18 :  False\n",
      "conv2d_19 :  False\n",
      "batch_normalization_13 :  False\n",
      "batch_normalization_15 :  False\n",
      "batch_normalization_18 :  False\n",
      "batch_normalization_19 :  False\n",
      "activation_13 :  False\n",
      "activation_15 :  False\n",
      "activation_18 :  False\n",
      "activation_19 :  False\n",
      "mixed1 :  False\n",
      "conv2d_23 :  False\n",
      "batch_normalization_23 :  False\n",
      "activation_23 :  False\n",
      "conv2d_21 :  False\n",
      "conv2d_24 :  False\n",
      "batch_normalization_21 :  False\n",
      "batch_normalization_24 :  False\n",
      "activation_21 :  False\n",
      "activation_24 :  False\n",
      "average_pooling2d_3 :  False\n",
      "conv2d_20 :  False\n",
      "conv2d_22 :  False\n",
      "conv2d_25 :  False\n",
      "conv2d_26 :  False\n",
      "batch_normalization_20 :  False\n",
      "batch_normalization_22 :  False\n",
      "batch_normalization_25 :  False\n",
      "batch_normalization_26 :  False\n",
      "activation_20 :  False\n",
      "activation_22 :  False\n",
      "activation_25 :  False\n",
      "activation_26 :  False\n",
      "mixed2 :  False\n",
      "conv2d_28 :  False\n",
      "batch_normalization_28 :  False\n",
      "activation_28 :  False\n",
      "conv2d_29 :  False\n",
      "batch_normalization_29 :  False\n",
      "activation_29 :  False\n",
      "conv2d_27 :  False\n",
      "conv2d_30 :  False\n",
      "batch_normalization_27 :  False\n",
      "batch_normalization_30 :  False\n",
      "activation_27 :  False\n",
      "activation_30 :  False\n",
      "max_pooling2d_3 :  False\n",
      "mixed3 :  False\n",
      "conv2d_35 :  False\n",
      "batch_normalization_35 :  False\n",
      "activation_35 :  False\n",
      "conv2d_36 :  False\n",
      "batch_normalization_36 :  False\n",
      "activation_36 :  False\n",
      "conv2d_32 :  False\n",
      "conv2d_37 :  False\n",
      "batch_normalization_32 :  False\n",
      "batch_normalization_37 :  False\n",
      "activation_32 :  False\n",
      "activation_37 :  False\n",
      "conv2d_33 :  False\n",
      "conv2d_38 :  False\n",
      "batch_normalization_33 :  False\n",
      "batch_normalization_38 :  False\n",
      "activation_33 :  False\n",
      "activation_38 :  False\n",
      "average_pooling2d_4 :  False\n",
      "conv2d_31 :  False\n",
      "conv2d_34 :  False\n",
      "conv2d_39 :  False\n",
      "conv2d_40 :  False\n",
      "batch_normalization_31 :  False\n",
      "batch_normalization_34 :  False\n",
      "batch_normalization_39 :  False\n",
      "batch_normalization_40 :  False\n",
      "activation_31 :  False\n",
      "activation_34 :  False\n",
      "activation_39 :  False\n",
      "activation_40 :  False\n",
      "mixed4 :  False\n",
      "conv2d_45 :  False\n",
      "batch_normalization_45 :  False\n",
      "activation_45 :  False\n",
      "conv2d_46 :  False\n",
      "batch_normalization_46 :  False\n",
      "activation_46 :  False\n",
      "conv2d_42 :  False\n",
      "conv2d_47 :  False\n",
      "batch_normalization_42 :  False\n",
      "batch_normalization_47 :  False\n",
      "activation_42 :  False\n",
      "activation_47 :  False\n",
      "conv2d_43 :  False\n",
      "conv2d_48 :  False\n",
      "batch_normalization_43 :  False\n",
      "batch_normalization_48 :  False\n",
      "activation_43 :  False\n",
      "activation_48 :  False\n",
      "average_pooling2d_5 :  False\n",
      "conv2d_41 :  False\n",
      "conv2d_44 :  False\n",
      "conv2d_49 :  False\n",
      "conv2d_50 :  False\n",
      "batch_normalization_41 :  False\n",
      "batch_normalization_44 :  False\n",
      "batch_normalization_49 :  False\n",
      "batch_normalization_50 :  False\n",
      "activation_41 :  False\n",
      "activation_44 :  False\n",
      "activation_49 :  False\n",
      "activation_50 :  False\n",
      "mixed5 :  False\n",
      "conv2d_55 :  False\n",
      "batch_normalization_55 :  False\n",
      "activation_55 :  False\n",
      "conv2d_56 :  False\n",
      "batch_normalization_56 :  False\n",
      "activation_56 :  False\n",
      "conv2d_52 :  False\n",
      "conv2d_57 :  False\n",
      "batch_normalization_52 :  False\n",
      "batch_normalization_57 :  False\n",
      "activation_52 :  False\n",
      "activation_57 :  False\n",
      "conv2d_53 :  False\n",
      "conv2d_58 :  False\n",
      "batch_normalization_53 :  False\n",
      "batch_normalization_58 :  False\n",
      "activation_53 :  False\n",
      "activation_58 :  False\n",
      "average_pooling2d_6 :  False\n",
      "conv2d_51 :  False\n",
      "conv2d_54 :  False\n",
      "conv2d_59 :  False\n",
      "conv2d_60 :  False\n",
      "batch_normalization_51 :  False\n",
      "batch_normalization_54 :  False\n",
      "batch_normalization_59 :  False\n",
      "batch_normalization_60 :  False\n",
      "activation_51 :  False\n",
      "activation_54 :  False\n",
      "activation_59 :  False\n",
      "activation_60 :  False\n",
      "mixed6 :  False\n",
      "conv2d_65 :  False\n",
      "batch_normalization_65 :  False\n",
      "activation_65 :  False\n",
      "conv2d_66 :  False\n",
      "batch_normalization_66 :  False\n",
      "activation_66 :  False\n",
      "conv2d_62 :  False\n",
      "conv2d_67 :  False\n",
      "batch_normalization_62 :  False\n",
      "batch_normalization_67 :  False\n",
      "activation_62 :  False\n",
      "activation_67 :  False\n",
      "conv2d_63 :  False\n",
      "conv2d_68 :  False\n",
      "batch_normalization_63 :  False\n",
      "batch_normalization_68 :  False\n",
      "activation_63 :  False\n",
      "activation_68 :  False\n",
      "average_pooling2d_7 :  False\n",
      "conv2d_61 :  False\n",
      "conv2d_64 :  False\n",
      "conv2d_69 :  False\n",
      "conv2d_70 :  False\n",
      "batch_normalization_61 :  False\n",
      "batch_normalization_64 :  False\n",
      "batch_normalization_69 :  False\n",
      "batch_normalization_70 :  False\n",
      "activation_61 :  False\n",
      "activation_64 :  False\n",
      "activation_69 :  False\n",
      "activation_70 :  False\n",
      "mixed7 :  False\n",
      "conv2d_73 :  False\n",
      "batch_normalization_73 :  False\n",
      "activation_73 :  False\n",
      "conv2d_74 :  False\n",
      "batch_normalization_74 :  False\n",
      "activation_74 :  False\n",
      "conv2d_71 :  False\n",
      "conv2d_75 :  False\n",
      "batch_normalization_71 :  False\n",
      "batch_normalization_75 :  False\n",
      "activation_71 :  False\n",
      "activation_75 :  False\n",
      "conv2d_72 :  False\n",
      "conv2d_76 :  False\n",
      "batch_normalization_72 :  False\n",
      "batch_normalization_76 :  False\n",
      "activation_72 :  False\n",
      "activation_76 :  False\n",
      "max_pooling2d_4 :  False\n",
      "mixed8 :  False\n",
      "conv2d_81 :  False\n",
      "batch_normalization_81 :  False\n",
      "activation_81 :  False\n",
      "conv2d_78 :  False\n",
      "conv2d_82 :  False\n",
      "batch_normalization_78 :  False\n",
      "batch_normalization_82 :  False\n",
      "activation_78 :  False\n",
      "activation_82 :  False\n",
      "conv2d_79 :  False\n",
      "conv2d_80 :  False\n",
      "conv2d_83 :  False\n",
      "conv2d_84 :  False\n",
      "average_pooling2d_8 :  False\n",
      "conv2d_77 :  False\n",
      "batch_normalization_79 :  False\n",
      "batch_normalization_80 :  False\n",
      "batch_normalization_83 :  False\n",
      "batch_normalization_84 :  False\n",
      "conv2d_85 :  False\n",
      "batch_normalization_77 :  False\n",
      "activation_79 :  False\n",
      "activation_80 :  False\n",
      "activation_83 :  False\n",
      "activation_84 :  False\n",
      "batch_normalization_85 :  False\n",
      "activation_77 :  False\n",
      "mixed9_0 :  False\n",
      "concatenate_1 :  False\n",
      "activation_85 :  False\n",
      "mixed9 :  False\n",
      "conv2d_90 :  False\n",
      "batch_normalization_90 :  False\n",
      "activation_90 :  False\n",
      "conv2d_87 :  False\n",
      "conv2d_91 :  False\n",
      "batch_normalization_87 :  False\n",
      "batch_normalization_91 :  False\n",
      "activation_87 :  False\n",
      "activation_91 :  False\n",
      "conv2d_88 :  False\n",
      "conv2d_89 :  False\n",
      "conv2d_92 :  False\n",
      "conv2d_93 :  False\n",
      "average_pooling2d_9 :  False\n",
      "conv2d_86 :  False\n",
      "batch_normalization_88 :  False\n",
      "batch_normalization_89 :  False\n",
      "batch_normalization_92 :  False\n",
      "batch_normalization_93 :  False\n",
      "conv2d_94 :  False\n",
      "batch_normalization_86 :  False\n",
      "activation_88 :  False\n",
      "activation_89 :  False\n",
      "activation_92 :  False\n",
      "activation_93 :  False\n",
      "batch_normalization_94 :  False\n",
      "activation_86 :  False\n",
      "mixed9_1 :  False\n",
      "concatenate_2 :  False\n",
      "activation_94 :  False\n",
      "mixed10 :  False\n",
      "global_average_pooling2d_1 :  True\n",
      "dense_1 :  True\n",
      "dense_2 :  True\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 230s - loss: 2.0870 - acc: 0.3006 - val_loss: 1.8965 - val_acc: 0.4250\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 227s - loss: 1.8024 - acc: 0.4486 - val_loss: 1.6371 - val_acc: 0.5150\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 227s - loss: 1.6245 - acc: 0.4930 - val_loss: 1.4899 - val_acc: 0.5640\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 227s - loss: 1.5166 - acc: 0.5226 - val_loss: 1.3922 - val_acc: 0.5810\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 227s - loss: 1.4319 - acc: 0.5448 - val_loss: 1.3024 - val_acc: 0.5930\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 227s - loss: 1.3918 - acc: 0.5478 - val_loss: 1.2548 - val_acc: 0.6200\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 227s - loss: 1.3484 - acc: 0.5604 - val_loss: 1.2256 - val_acc: 0.5990\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 227s - loss: 1.3098 - acc: 0.5662 - val_loss: 1.1574 - val_acc: 0.6340\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 227s - loss: 1.2717 - acc: 0.5818 - val_loss: 1.1817 - val_acc: 0.6160\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 227s - loss: 1.2468 - acc: 0.5868 - val_loss: 1.1115 - val_acc: 0.6310\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 366s - loss: 1.1151 - acc: 0.6278 - val_loss: 0.8498 - val_acc: 0.7120\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 364s - loss: 0.9272 - acc: 0.6896 - val_loss: 0.8035 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 364s - loss: 0.7979 - acc: 0.7414 - val_loss: 0.7634 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 364s - loss: 0.7279 - acc: 0.7602 - val_loss: 0.6825 - val_acc: 0.7620\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 364s - loss: 0.6840 - acc: 0.7772 - val_loss: 0.6948 - val_acc: 0.7790\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 364s - loss: 0.6060 - acc: 0.8024 - val_loss: 0.6900 - val_acc: 0.7830\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 364s - loss: 0.5571 - acc: 0.8192 - val_loss: 0.6952 - val_acc: 0.7840\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 364s - loss: 0.5145 - acc: 0.8306 - val_loss: 0.7060 - val_acc: 0.7850\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 364s - loss: 0.4856 - acc: 0.8454 - val_loss: 0.6554 - val_acc: 0.8100\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 364s - loss: 0.4489 - acc: 0.8502 - val_loss: 0.7246 - val_acc: 0.7920\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Epoch 1/10\n",
    "1250/1250 [==============================] - 230s - loss: 2.0870 - acc: 0.3006 - val_loss: 1.8965 - val_acc: 0.4250\n",
    "Epoch 2/10\n",
    "1250/1250 [==============================] - 227s - loss: 1.8024 - acc: 0.4486 - val_loss: 1.6371 - val_acc: 0.5150\n",
    "Epoch 3/10\n",
    "1250/1250 [==============================] - 227s - loss: 1.6245 - acc: 0.4930 - val_loss: 1.4899 - val_acc: 0.5640\n",
    "Epoch 4/10\n",
    "1250/1250 [==============================] - 227s - loss: 1.5166 - acc: 0.5226 - val_loss: 1.3922 - val_acc: 0.5810\n",
    "Epoch 5/10\n",
    "1250/1250 [==============================] - 227s - loss: 1.4319 - acc: 0.5448 - val_loss: 1.3024 - val_acc: 0.5930\n",
    "Epoch 6/10\n",
    "1250/1250 [==============================] - 227s - loss: 1.3918 - acc: 0.5478 - val_loss: 1.2548 - val_acc: 0.6200\n",
    "Epoch 7/10\n",
    "1250/1250 [==============================] - 227s - loss: 1.3484 - acc: 0.5604 - val_loss: 1.2256 - val_acc: 0.5990\n",
    "Epoch 8/10\n",
    "1250/1250 [==============================] - 227s - loss: 1.3098 - acc: 0.5662 - val_loss: 1.1574 - val_acc: 0.6340\n",
    "Epoch 9/10\n",
    "1250/1250 [==============================] - 227s - loss: 1.2717 - acc: 0.5818 - val_loss: 1.1817 - val_acc: 0.6160\n",
    "Epoch 10/10\n",
    "1250/1250 [==============================] - 227s - loss: 1.2468 - acc: 0.5868 - val_loss: 1.1115 - val_acc: 0.6310\n",
    "Epoch 1/10\n",
    "1250/1250 [==============================] - 366s - loss: 1.1151 - acc: 0.6278 - val_loss: 0.8498 - val_acc: 0.7120\n",
    "Epoch 2/10\n",
    "1250/1250 [==============================] - 364s - loss: 0.9272 - acc: 0.6896 - val_loss: 0.8035 - val_acc: 0.7500\n",
    "Epoch 3/10\n",
    "1250/1250 [==============================] - 364s - loss: 0.7979 - acc: 0.7414 - val_loss: 0.7634 - val_acc: 0.7500\n",
    "Epoch 4/10\n",
    "1250/1250 [==============================] - 364s - loss: 0.7279 - acc: 0.7602 - val_loss: 0.6825 - val_acc: 0.7620\n",
    "Epoch 5/10\n",
    "1250/1250 [==============================] - 364s - loss: 0.6840 - acc: 0.7772 - val_loss: 0.6948 - val_acc: 0.7790\n",
    "Epoch 6/10\n",
    "1250/1250 [==============================] - 364s - loss: 0.6060 - acc: 0.8024 - val_loss: 0.6900 - val_acc: 0.7830\n",
    "Epoch 7/10\n",
    "1250/1250 [==============================] - 364s - loss: 0.5571 - acc: 0.8192 - val_loss: 0.6952 - val_acc: 0.7840\n",
    "Epoch 8/10\n",
    "1250/1250 [==============================] - 364s - loss: 0.5145 - acc: 0.8306 - val_loss: 0.7060 - val_acc: 0.7850\n",
    "Epoch 9/10\n",
    "1250/1250 [==============================] - 364s - loss: 0.4856 - acc: 0.8454 - val_loss: 0.6554 - val_acc: 0.8100\n",
    "Epoch 10/10\n",
    "1250/1250 [==============================] - 364s - loss: 0.4489 - acc: 0.8502 - val_loss: 0.7246 - val_acc: 0.7920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
