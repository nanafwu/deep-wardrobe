{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import cv2\n",
    "\n",
    "\n",
    "LOG_DIR = 'tensorboard_outfits'\n",
    "METADATA_FILE = LOG_DIR + '/outfits_metadata.tsv'\n",
    "NAME_TO_VISUALISE_VARIABLE = \"style_embedding\"\n",
    "TO_EMBED_COUNT = 500\n",
    "product_feats_file = 'data-outfits/outfit_product_features_small.tsv'\n",
    "product_ids_file = 'data-outfits/outfit_products_small.tsv'\n",
    "outfit_combinations_file = 'data-outfits/outfit_combinations_small.tsv'\n",
    "IMAGE_SIZE=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_product_to_features(product_feats_file):\n",
    "    product_to_feats = {}\n",
    "    rf_feature_import_file = 'rf_feat_import.dat'\n",
    "    all_feat_importances = np.load(rf_feature_import_file)\n",
    "    top_features = sorted(list(zip(range(0, 1024), all_feat_importances)), key=lambda tup: tup[1], reverse=True)\n",
    "    bottom_feature_indexes = [f[0] for f in top_features[100:]]\n",
    "    with open(product_feats_file, 'r') as tsvfile:\n",
    "        tsvreader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        for row in tsvreader:\n",
    "            product_id = row[0]\n",
    "            feats_stored = [float(n) for n in row[1:]]\n",
    "            feats_reduced = np.delete(feats_stored, bottom_feature_indexes)\n",
    "            feats = np.array([feats_reduced])\n",
    "            product_to_feats[product_id] = feats\n",
    "    return product_to_feats\n",
    "\n",
    "\n",
    "def make_data_inputs(outfit_combo_file, product_to_features):\n",
    "    print('Reading file ', outfit_combo_file)\n",
    "    X_product_features = []\n",
    "    metadata = []\n",
    "    with open(outfit_combo_file, 'r') as f:\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            product1_id = l[2]\n",
    "            product2_id = l[5]\n",
    "            #product3_id = l[8]\n",
    "            collection_id = l[1]\n",
    "            product1_feat = product_to_features[product1_id]\n",
    "            product2_feat = product_to_features[product2_id]\n",
    "            #product3_feat = product_to_features[product3_id]\n",
    "\n",
    "            merged_feat = np.concatenate((product1_feat, product2_feat), axis=1)\n",
    "            metadata.append([collection_id, ])\n",
    "            X_product_features.append(merged_feat[0])\n",
    "            \n",
    "    print('Saving Metadata')\n",
    "    with open(METADATA_FILE, 'w') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        #writer.writerow(['Id'])\n",
    "        for m in metadata:\n",
    "            writer.writerow(m)\n",
    "            f.flush()\n",
    "    return np.array(X_product_features), metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken from: https://github.com/tensorflow/tensorflow/issues/6322\n",
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    #data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prods_to_feats = get_product_to_features(product_feats_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prods_to_feats['641336745'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  data-outfits/outfit_combinations_small.tsv\n",
      "Saving Metadata\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features, X_collection_ids = make_data_inputs(outfit_combinations_file, prods_to_feats)\n",
    "# X_prod_ids = [p[0] for p in X_prods]\n",
    "# X_prod_categories = [p[1] for p in X_prods]\n",
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_image_sprites(outfit_combo_file):\n",
    "    img_data=[]\n",
    "    data_path = 'data-outfits/images_collections'\n",
    "    with open(outfit_combo_file, 'r') as f:\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            collection_id = l[1]\n",
    "            input_img=cv2.imread(data_path + '/' + collection_id + '.jpg')\n",
    "            input_img_resize=cv2.resize(input_img,(IMAGE_SIZE,IMAGE_SIZE)) # you can choose what size to resize your data\n",
    "            img_data.append(input_img_resize)\n",
    "    img_data = np.array(img_data)\n",
    "    sprite = images_to_sprite(img_data)\n",
    "    cv2.imwrite(os.path.join(LOG_DIR, 'sprite_classes.png'), sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_image_sprites(outfit_combinations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorboard_outfits/model.ckpt-1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_var = tf.Variable(X_features, name=NAME_TO_VISUALISE_VARIABLE)\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "# Specify where you find the metadata\n",
    "embedding.metadata_path = METADATA_FILE\n",
    "\n",
    "# Specify where you find the sprite \n",
    "embedding.sprite.image_path = 'sprite_classes.png' #path_for_mnist_sprites #'mnistdigits.png'\n",
    "embedding.sprite.single_image_dim.extend([IMAGE_SIZE, IMAGE_SIZE])\n",
    "\n",
    "# Say that you want to visualise the embeddings\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir tensorboard_outfits\n",
    "# https://github.com/anujshah1003/Tensorboard-own-image-data-image-features-embedding-visualization/blob/master/own-data-embedding-visualization.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
