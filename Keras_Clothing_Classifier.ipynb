{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape = (224,224,3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for layer in base_model.layers:\n",
    "#     print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 134,301,514\n",
      "Trainable params: 119,586,826\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, name='fc1')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(4096, name='fc2')(x)\n",
    "\n",
    "\n",
    "#predictions = Dense(2, activation=\"softmax\") (x)\n",
    "#predictions = Dense(1, activation=\"sigmoid\") (x)\n",
    "x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "\n",
    "model_final = Model(inputs=base_model.input, outputs=x)\n",
    "#model_final.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.sgd(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "model_final.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=0.00001), metrics=[\"accuracy\"])\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "311/312 [============================>.] - ETA: 0s - loss: 1.4337 - acc: 0.5287Epoch 00000: val_acc improved from -inf to 0.53024, saving model to vgg16_clothing_classifier_1.h5\n",
      "312/312 [==============================] - 264s - loss: 1.4333 - acc: 0.5288 - val_loss: 1.4104 - val_acc: 0.5302\n",
      "Epoch 2/10\n",
      "114/312 [=========>....................] - ETA: 139s - loss: 0.9560 - acc: 0.6848"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bca4bcfab487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             callbacks = [checkpoint, early])\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights_file = 'vgg16_clothing_classifier_1.h5'\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                  shear_range =.2,\n",
    "                                  zoom_range = .2,\n",
    "                                  horizontal_flip = True)\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = \"data/validation\"\n",
    "nb_validation_samples = 1000\n",
    "nb_train_samples = 5000\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_data_dir,\n",
    "                target_size=(img_width, img_height),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "                                validation_data_dir,\n",
    "                                target_size = (img_height, img_width),\n",
    "                                batch_size=batch_size,\n",
    "                                class_mode = \"categorical\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_file, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "history = model_final.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples//batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=nb_validation_samples//batch_size,\n",
    "            verbose=1,\n",
    "            workers=4,\n",
    "            callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDGOMMV75/0EeoE8FKxvQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b5d122828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Activation = Relu, no dropout, 256 per layer, 2 layers\n",
    "- Epoch 1/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.7618 - acc: 0.4528\n",
    "Epoch 00000: val_acc improved from -inf to 0.53327, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 196s - loss: 1.7600 - acc: 0.4533 - val_loss: 1.5181 - val_acc: 0.5333\n",
    "- Epoch 2/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.2145 - acc: 0.6290\n",
    "Epoch 00001: val_acc improved from 0.53327 to 0.59350, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 195s - loss: 1.2146 - acc: 0.6290 - val_loss: 1.2554 - val_acc: 0.5935\n",
    "- Epoch 3/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.0157 - acc: 0.6752\n",
    "Epoch 00002: val_acc improved from 0.59350 to 0.60976, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 195s - loss: 1.0155 - acc: 0.6747 - val_loss: 1.1297 - val_acc: 0.6098\n",
    "- Epoch 4/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.8905 - acc: 0.7176\n",
    "Epoch 00003: val_acc improved from 0.60976 to 0.63008, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 195s - loss: 0.8908 - acc: 0.7175 - val_loss: 1.0924 - val_acc: 0.6301\n",
    "- Epoch 5/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.8147 - acc: 0.7381\n",
    "Epoch 00004: val_acc improved from 0.63008 to 0.67988, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 195s - loss: 0.8159 - acc: 0.7376 - val_loss: 0.9710 - val_acc: 0.6799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation = Relu, dropout = 0.2 , 256 per layer, 2 layers\n",
    "- Epoch 1/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.8920 - acc: 0.3559 Epoch 00000: val_acc improved from -inf to 0.50000, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 196s - loss: 1.8911 - acc: 0.3560 - val_loss: 1.5996 - val_acc: 0.5000\n",
    "- Epoch 2/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.4099 - acc: 0.5324\n",
    "Epoch 00001: val_acc improved from 0.50000 to 0.57114, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 195s - loss: 1.4097 - acc: 0.5327 - val_loss: 1.3624 - val_acc: 0.5711\n",
    "- Epoch 3/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.1902 - acc: 0.6154\n",
    "Epoch 00002: val_acc improved from 0.57114 to 0.60976, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 195s - loss: 1.1899 - acc: 0.6154 - val_loss: 1.1734 - val_acc: 0.6098\n",
    "- Epoch 4/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.0636 - acc: 0.6555\n",
    "Epoch 00003: val_acc improved from 0.60976 to 0.61890, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 195s - loss: 1.0633 - acc: 0.6557 - val_loss: 1.1114 - val_acc: 0.6189\n",
    "- Epoch 5/5\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.9644 - acc: 0.6855\n",
    "Epoch 00004: val_acc improved from 0.61890 to 0.64837, saving model to vgg16_1.h5\n",
    "312/312 [==============================] - 195s - loss: 0.9647 - acc: 0.6855 - val_loss: 1.0660 - val_acc: 0.6484\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation = Relu, dropout = 0.2 , 4096 per layer, 2 layers, 10 epochs\n",
    "- Epoch 1/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.6946 - acc: 0.4343Epoch 00000: val_acc improved from -inf to 0.57560, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 229s - loss: 1.6939 - acc: 0.4351 - val_loss: 1.4136 - val_acc: 0.5756\n",
    "- Epoch 2/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.1629 - acc: 0.6308Epoch 00001: val_acc improved from 0.57560 to 0.59553, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 234s - loss: 1.1622 - acc: 0.6300 - val_loss: 1.1944 - val_acc: 0.5955\n",
    "- Epoch 3/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.9827 - acc: 0.6851Epoch 00002: val_acc improved from 0.59553 to 0.60569, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 235s - loss: 0.9821 - acc: 0.6853 - val_loss: 1.1276 - val_acc: 0.6057\n",
    "- Epoch 4/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.8713 - acc: 0.7221Epoch 00003: val_acc improved from 0.60569 to 0.65142, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 235s - loss: 0.8709 - acc: 0.7226 - val_loss: 0.9978 - val_acc: 0.6514\n",
    "- Epoch 5/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.7974 - acc: 0.7428Epoch 00004: val_acc improved from 0.65142 to 0.65549, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 235s - loss: 0.7966 - acc: 0.7432 - val_loss: 1.0205 - val_acc: 0.6555\n",
    "- Epoch 6/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.7460 - acc: 0.7556Epoch 00005: val_acc improved from 0.65549 to 0.66463, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 235s - loss: 0.7471 - acc: 0.7556 - val_loss: 0.9355 - val_acc: 0.6646\n",
    "- Epoch 7/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.6910 - acc: 0.7737Epoch 00006: val_acc improved from 0.66463 to 0.67276, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 235s - loss: 0.6905 - acc: 0.7740 - val_loss: 0.9172 - val_acc: 0.6728\n",
    "- Epoch 8/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.6558 - acc: 0.7902Epoch 00007: val_acc did not improve\n",
    "312/312 [==============================] - 226s - loss: 0.6557 - acc: 0.7903 - val_loss: 0.9853 - val_acc: 0.6606\n",
    "- Epoch 9/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.6148 - acc: 0.8069Epoch 00008: val_acc improved from 0.67276 to 0.67785, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 234s - loss: 0.6137 - acc: 0.8073 - val_loss: 0.8573 - val_acc: 0.6778\n",
    "- Epoch 10/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.5847 - acc: 0.8143Epoch 00009: val_acc did not improve\n",
    "312/312 [==============================] - 226s - loss: 0.5844 - acc: 0.8145 - val_loss: 0.9304 - val_acc: 0.6748"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation = None, dropout = 0.2 , 4096 per layer, 2 layers, 10 epochs\n",
    "Found 1000 images belonging to 10 classes.\n",
    "- Epoch 1/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 1.5095 - acc: 0.5028Epoch 00000: val_acc improved from -inf to 0.56048, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 245s - loss: 1.5080 - acc: 0.5032 - val_loss: 1.2566 - val_acc: 0.5605\n",
    "- Epoch 2/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.9448 - acc: 0.6819Epoch 00001: val_acc improved from 0.56048 to 0.63008, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 234s - loss: 0.9436 - acc: 0.6825 - val_loss: 1.0815 - val_acc: 0.6301\n",
    "- Epoch 3/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.7636 - acc: 0.7434Epoch 00002: val_acc improved from 0.63008 to 0.64939, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 234s - loss: 0.7633 - acc: 0.7432 - val_loss: 0.9501 - val_acc: 0.6494\n",
    "- Epoch 4/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.6875 - acc: 0.7715Epoch 00003: val_acc improved from 0.64939 to 0.66870, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 234s - loss: 0.6888 - acc: 0.7708 - val_loss: 0.9157 - val_acc: 0.6687\n",
    "- Epoch 5/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.5902 - acc: 0.8016Epoch 00004: val_acc did not improve\n",
    "312/312 [==============================] - 226s - loss: 0.5889 - acc: 0.8023 - val_loss: 1.0242 - val_acc: 0.6524\n",
    "- Epoch 6/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.5565 - acc: 0.8079Epoch 00005: val_acc improved from 0.66870 to 0.71037, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 234s - loss: 0.5558 - acc: 0.8081 - val_loss: 0.8513 - val_acc: 0.7104\n",
    "- Epoch 7/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.5050 - acc: 0.8338Epoch 00006: val_acc did not improve\n",
    "312/312 [==============================] - 226s - loss: 0.5053 - acc: 0.8339 - val_loss: 0.9394 - val_acc: 0.6646\n",
    "- Epoch 8/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8418Epoch 00007: val_acc improved from 0.71037 to 0.71138, saving model to vgg16_clothing_classifier_0.h5\n",
    "312/312 [==============================] - 234s - loss: 0.4769 - acc: 0.8419 - val_loss: 0.8515 - val_acc: 0.7114\n",
    "- Epoch 9/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.4295 - acc: 0.8579Epoch 00008: val_acc did not improve\n",
    "312/312 [==============================] - 226s - loss: 0.4289 - acc: 0.8584 - val_loss: 0.9653 - val_acc: 0.6514\n",
    "- Epoch 10/10\n",
    "311/312 [============================>.] - ETA: 0s - loss: 0.3952 - acc: 0.8740Epoch 00009: val_acc did not improve\n",
    "312/312 [==============================] - 226s - loss: 0.3949 - acc: 0.8738 - val_loss: 0.8268 - val_acc: 0.7063\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
